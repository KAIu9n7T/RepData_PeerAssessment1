b = c(3,3,4,4),
fFull = c(100, 200, 300, 400))
Now we just enter some information into FillIn about what the data set names are, what variables we want to fill in, and what variables to join the data sets on.
# Fill in missing f's from naDF with values from fillDF
FilledInData <- FillIn(D1 = naDF, D2 = fillDF,
Var1 = "fNA", Var2 = "fFull", KeyVar = c("a", "b"))
naDF
fillDF
FilledInData
?ldply
suppressMessages(suppressWarnings(library(caret)))
suppressMessages(suppressWarnings(library(rattle)))
suppressMessages(suppressWarnings(library(plyr)))
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(doParallel)))
registerDoParallel(cores=2)
data <- read.csv("C:\\Users\\Jenner\\Desktop\\fbdata\\SP1.csv")
data <- mutate(data, Date = as.Date(Date, "%d/%m/%y"))
smallData <- select(data, Date:FTAG, HS:AR)
smallData <- rename(smallData, HGFT = FTHG, AGFT = FTAG)
smallData <- select(data, Date:FTAG, HS:AR)
smallData <- rename(smallData, HGFT = FTHG, AGFT = FTAG)
?merge
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
dim(vowel.train)
dim(vowel.test)
head(vowel.train)
vowel.train <- factor(vowel.train)
head(vowel.train)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
head(vowel.train)
head(vowel.test)
str(vowel.train)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
###
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
###
set.seed(33833)
###
mod1 <- train(y~., data=vowel.train, method="rf", prox=T)
mod2 <- train(y~., data=vowel.train, method="gbm", verbose=F)
pred1 <- predict(mod1, test.vowel)
pred2 <- predict(mod2, test.vowel)
confusionMatrix(pred1, test.vowel$y)
confusionMatrix(pred2, test.vowel$y)
pred1 <- predict(mod1, vowel$test)
pred2 <- predict(mod2, vowel$test)
confusionMatrix(pred1, test.vowel$y)
confusionMatrix(pred2, test.vowel$y)
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
pred1
confusionMatrix(pred1, vowel.test$y)
confusionMatrix(pred2, vowel.test$y)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
###
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
###
set.seed(33833)
###
mod1 <- train(y~., data=vowel.train, method="rf", prox=T)
mod2 <- train(y~., data=vowel.train, method="gbm", verbose=F)
###
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
###
confusionMatrix(pred1, vowel.test$y)
confusionMatrix(pred2, vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
###
set.seed(62433)
###
mod1 <- train(diagnosis~., method="rf", data=training,
trControl=trainControl(method="cv"), number=3)
mod2 <- train(diagnosis~., method="gbm", data=training)
mod3 <- train(diagnosis~., method="lda", data=training)
###
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
###
predDF <- data.frame(pred1, pred2, pred3,
diagnosis=testing$diagnosis)
###
combModFit <- train(diagnosis~., method="gam", data=predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(combPred, testing$diagnosis)
combPred
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
###
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(combPred, testing$diagnosis)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
###
set.seed(62433)
###
mod1 <- train(diagnosis~., method="rf", data=training,
trControl=trainControl(method="cv"), number=3)
mod2 <- train(diagnosis~., method="gbm", data=training)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
###
set.seed(62433)
###
mod1 <- train(diagnosis~., method="rf", data=training,
trControl=trainControl(method="cv"), number=3)
mod2 <- train(diagnosis~., method="gbm", data=training)
mod3 <- train(diagnosis~., method="lda", data=training)
###
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
###
predDF <- data.frame(pred1, pred2, pred3,
diagnosis=testing$diagnosis)
###
combModFit <- train(diagnosis~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
###
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
confusionMatrix(combPred, testing$diagnosis)
?train
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(233)
###
?plot.enet
?plot.enet
install.packages("enet")
head(training)
library(enet)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(233)
###
mod <- train(CompressiveStrength~., data=training, method="lasso")
install.packages("enet")
install.packages("elasticnet")
library(elasticnet)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(233)
###
mod <- train(CompressiveStrength~., data=training, method="lasso")
library(elasticnet)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(233)
###
mod <- train(CompressiveStrength~., data=training, method="lasso")
?plot.enet
plot.enet(mod$finalModel, xvar=c("penalty"), use.color = TRUE)
?plot.enet
plot.enet(mod$finalModel, xvar=c("penalty"), use.color = TRUE)
?dowload.file
?dowloadfile
?dowload
?filedowload
?file.dowload
download.url
download
library(lubridate)  # For year() function below
dat = read.csv("C:\\Users\\Jenner\\Documents\\Coursera\\20150706-
20150801 Practical Machine Learning\\Week 4\\gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(forecast)
install.packages("forecast")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("C:\\Users\\Jenner\\Documents\\Coursera\\20150706-
20150801 Practical Machine Learning\\Week 4\\gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
install.packages("forecast")
library(forecast)
install.packages("forecast")
library(forecast)
forecast
bats
install.packages("timeDate")
install.packages("timeDate")
library(forecast)
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(325)
###
mod <- svm
###
svm
?svm
head(training)
mod <- svm(CompressiveStrength~., data=training)
pred <- predict(mod, testing)
str(pred)
?svm
pred
sqrt(sum(pred-concrete$CompressiveStrength)^2)
sqrt(sum(pred-testing$CompressiveStrength)^2)
sqrt(sum(pred-testing$CompressiveStrength)^2)/length(pred)
rmse(pred, testing$CompressiveStrength)
install.packages("hydroGOF")
sqrt(sum(pre-testing$CompressiveStrength)^2/length(pred))
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pre-testing$CompressiveStrength)^2/length(pred))
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
library(e1071)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
###
2.69^2
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
library(e1071)
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
###
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
library(e1071)
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
###
length(pred)
dim(testing)
sqrt(sum(pred-testing$CompressiveStrength)^2)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
library(e1071)
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2)
###
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
library(e1071)
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2)
###
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
head(training)
pred <- predict(mod, testing[,-9])
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
head(training)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p =
3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
###
library(e1071)
set.seed(325)
###
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing[,-9])
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
?svm
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod <- svm(CompressiveStrength~., data=training)
###
pred <- predict(mod, testing)
names(pred) <- NULL
sqrt(sum(pred-testing$CompressiveStrength)^2/length(pred))
sqrt(sum((testing$CompressiveStrength-pred)^2)/length(pred))
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
###
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
###
set.seed(33833)
###
mod1 <- train(y~., data=vowel.train, method="rf", prox=T)
mod2 <- train(y~., data=vowel.train, method="gbm", verbose=F)
###
pred1 <- predict(mod1, vowel.test)
pred2 <- predict(mod2, vowel.test)
###
confusionMatrix(pred1, pred2, vowel.test$y)
confusionMatrix(pred2, vowel.test$y)
paste(1:3)
paste(c(1:3,rep(NA,2))
)
paste(c(1:3))
c(paste(c(1:3)), rep(NA,3))
sample(c(paste(c(1:3)), rep(NA,3)))
sample(c(paste(c(1:3)), rep(NA,3)))
as.numeric(sample(c(paste(c(1:3)), rep(NA,3))))
as.numeric(sample(c(paste(c(1:3)), rep(NA,3))))
sample(0:9, size=7)
sample(0:9, size=3)
symbols
symbols()
symbols[1]
symbols
?symbols
sample(c(letters, LETTERS, 0:11, c("!","#", "$","%","&", "(", ")")), size=12)
sample(c(letters, LETTERS, 0:11, c("!","#", "$","%","&", "(", ")")), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
sample(c(letters, LETTERS, 0:11, "!", "#", "$", "%", "&","("), size=12)
?to.weekly
library(zoo)
install.packages("forecast")
library(forecast)
bst
bat
bats
library(forecast)
library(zoo)
seq(Sys.Date(), by='day', length=365)
tt <- seq(Sys.Date(), by='day', length=365)
data.frame(A=runif(365), B=rnorm(365), C=1:365)
vals <- data.frame(A=runif(365), B=rnorm(365), C=1:365)
vals
zoo(vals, tt)
z <- zoo(vals, tt)
z
?to.monthly
remove.packages("forecast")
install.packages("forecast")
library(forecast)
library(forecast)
library(forecast)
bats
?to.monthly
library(quantmod)
install.packages("quantmod")
library(quantmod)
to.monthly
?to.monthly
irir
iris
?iris
sample(c(letters, LETTERS, 0:11), size=12)
setwd("C:\\Users\\Jenner\\Desktop\\Reproducible\\RepData_PeerAssessment1")
library(knitr)
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
knit2html("As1ReprRes.Rmd")
